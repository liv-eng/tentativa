# -*- coding: utf-8 -*-
"""Kaggle- Cancer Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TvKFLTRO6DJqcmh5q5VpiUVJPwFaF1GF

# Histopathologic Cancer Detection

**Resumo da Descrição do Conjunto de Dados**

O conjunto de dados consiste em imagens médicas utilizadas para treinar e testar um modelo de aprendizado de máquina capaz de identificar a presença de tumores.

Principais características:

Imagens: São imagens em RGB (vermelho, verde, azul) com resolução de 96x96 pixels.
Rótulos: Cada imagem possui um rótulo binário (0 ou 1) indicando a ausência ou presença de um tumor, respectivamente.
Divisão dos dados: Os dados são divididos em um conjunto de treinamento (para treinar o modelo) e um conjunto de teste (para avaliar a performance do modelo).
Região de Interesse: Apenas a região central de 32x32 pixels de cada imagem é relevante para a classificação.
Objetivo:

Treinar um modelo: Utilizar o conjunto de treinamento para ensinar o modelo a identificar padrões nas imagens que indicam a presença de tumores.
Realizar previsões: Utilizar o conjunto de teste para avaliar a capacidade do modelo de prever corretamente a presença ou ausência de tumores em novas imagens.
Em resumo, o conjunto de dados fornece as imagens e os rótulos necessários para desenvolver e avaliar um modelo de classificação de imagens médicas, com o objetivo de auxiliar no diagnóstico de tumores.

Passo 1: EDA
"""

from google.colab import files
uploaded = files.upload()

import zipfile

# Descompactar o arquivo
with zipfile.ZipFile('train_labels.csv.zip', 'r') as zip_ref:
    zip_ref.extractall('.')  # Extrai no diretório atual

import os

# Listar arquivos no diretório atual
print(os.listdir())

import pandas as pd

# Carregar o arquivo CSV
train_labels = pd.read_csv('train_labels.csv')

# Mostrar as primeiras linhas do dataframe
print(train_labels.head())

print(train_labels.shape)  # Número de linhas e colunas

print(train_labels['label'].value_counts())
train_labels['label'].value_counts().plot(kind='bar', title='Distribuição de Classes')

print(train_labels.isnull().sum())  # Valores ausentes

from google.colab import drive

# Montar o Google Drive
drive.mount('/content/drive')

from google.colab import drive
drive.mount('/content/drive')
# Verifique o conteúdo de "MyDrive"
print(os.listdir('/content/drive/MyDrive'))
drive.mount('/content/drive', force_remount=True)

import zipfile
import os
import pandas as pd  # Certifique-se de importar o Pandas

# Caminho para o arquivo ZIP
zip_path = '/content/drive/MyDrive/kaggle/train_labels.csv.zip'

# Descompactar o arquivo ZIP
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall('/content/drive/MyDrive/kaggle')

# Verifique se o arquivo foi descompactado
print("Arquivos na pasta após descompactação:", os.listdir('/content/drive/MyDrive/kaggle'))

# Caminho para o arquivo CSV descompactado
csv_path = '/content/drive/MyDrive/kaggle/train_labels.csv'

# Ler o arquivo CSV com o Pandas
train_labels = pd.read_csv(csv_path)

# Exibir as primeiras linhas do dataframe
print(train_labels.head())

train_labels.info()

train_labels.describe()

train_labels['label'].value_counts()

import os

zip_image_path = '/content/drive/MyDrive/kaggle/train.zip'
print(f"Tamanho do arquivo ZIP: {os.path.getsize(zip_image_path) / (1024 * 1024):.2f} MB")

temp_extract_dir = '/content/train'

with zipfile.ZipFile(zip_image_path, 'r') as zip_ref:
    zip_ref.extractall(temp_extract_dir)

# Verificar os arquivos extraídos
print(os.listdir(temp_extract_dir)[:10])

with zipfile.ZipFile(zip_image_path, 'r') as zip_ref:
    bad_file = zip_ref.testzip()
    if bad_file is not None:
        print(f"Arquivo corrompido: {bad_file}")
    else:
        print("O arquivo ZIP está íntegro.")

import os

zip_size = os.path.getsize(zip_image_path) / (1024**2)  # Tamanho em MB
print(f"Tamanho do arquivo ZIP: {zip_size:.2f} MB")

import zipfile
import os

# Caminho do arquivo ZIP e diretório de extração
zip_image_path = '/content/drive/MyDrive/kaggle/train.zip'
extract_dir = '/content/drive/MyDrive/kaggle/train_extracted'

# Extração com progresso
with zipfile.ZipFile(zip_image_path, 'r') as zip_ref:
    all_files = zip_ref.namelist()
    total_files = len(all_files)
    print(f"Total de arquivos no ZIP: {total_files}")

    for i, file in enumerate(all_files):
        zip_ref.extract(file, extract_dir)
        if (i + 1) % 1000 == 0:  # Atualize o progresso a cada 1000 arquivos
            print(f"{i + 1}/{total_files} arquivos extraídos...")

    print("Extração concluída!")

import zipfile

# Diretório temporário para testar a extração
temp_extract_dir = '/content/drive/MyDrive/kaggle/train_partial'

with zipfile.ZipFile(zip_image_path, 'r') as zip_ref:
    all_files = zip_ref.namelist()
    print(f"Total de arquivos no ZIP: {len(all_files)}")

    # Extraia apenas os primeiros 100 arquivos
    for file in all_files[:100]:
        zip_ref.extract(file, temp_extract_dir)

    print("100 arquivos extraídos para teste.")

from google.colab import drive

# Tente montar o Google Drive novamente
drive.mount('/content/drive')

# Verificar se a pasta MyDrive está acessível
print(os.listdir('/content/drive/MyDrive'))

import os

# Verificar arquivos no diretório de seu Google Drive
print(os.listdir('/content/drive/MyDrive/kaggle'))

import zipfile
import os

# Caminho do arquivo ZIP
zip_image_path = '/content/drive/MyDrive/kaggle/train.zip'

# Diretório temporário para extração das imagens
temp_extract_dir = '/content/train_extracted'

# Verifique se o arquivo ZIP existe antes de tentar extrair
if os.path.exists(zip_image_path):
    with zipfile.ZipFile(zip_image_path, 'r') as zip_ref:
        zip_ref.extractall(temp_extract_dir)

    # Verifique se os arquivos foram extraídos com sucesso
    extracted_files = os.listdir(temp_extract_dir)
    if extracted_files:
        print(f"Arquivos extraídos com sucesso: {len(extracted_files)} arquivos.")
        print("Primeiros 10 arquivos extraídos:", extracted_files[:10])
    else:
        print("Nenhum arquivo foi extraído. Verifique se o ZIP contém os dados.")
else:
    print("Arquivo ZIP não encontrado. Verifique o caminho do arquivo.")

import cv2
import matplotlib.pyplot as plt

# Defina o diretório de extração das imagens
image_dir = '/content/train_extracted'  # ou o caminho correto do seu diretório

# Carregar e exibir algumas imagens
image_files = os.listdir(image_dir)[:5]  # Exibindo as 5 primeiras imagens

for img_file in image_files:
    img_path = os.path.join(image_dir, img_file)
    img = cv2.imread(img_path)  # Ler a imagem com OpenCV
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Converter de BGR para RGB (OpenCV padrão)

    # Exibir a imagem
    plt.figure(figsize=(5, 5))
    plt.imshow(img)
    plt.title(img_file)
    plt.axis('off')  # Não exibir eixos
    plt.show()

import pandas as pd

# Caminho para o arquivo CSV com os rótulos
csv_path = '/content/drive/MyDrive/kaggle/train_labels.csv'

# Carregar o CSV
train_labels = pd.read_csv(csv_path)

# Verificar as primeiras linhas
print(train_labels.head())

import cv2

def resize_image(image_path, size=(32, 32)):
    img = cv2.imread(image_path)
    img_resized = cv2.resize(img, size)
    return img_resized

# Aplicar a função a todas as imagens
resized_images = []
for img_file in image_files:  # Pode percorrer todas as imagens
    img_path = os.path.join(image_dir, img_file)
    resized_img = resize_image(img_path)
    resized_images.append(resized_img)

import numpy as np

# Converter lista de imagens para um array NumPy e normalizar
resized_images = np.array(resized_images) / 255.0  # Normalizar para [0, 1]

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Criar um gerador de aumento de dados
datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

# Ajustar o gerador aos dados (com imagens normalizadas)
datagen.fit(resized_images)

import pandas as pd

# Caminho para o arquivo de rótulos
labels_path = '/content/drive/MyDrive/kaggle/train_labels.csv'

# Carregar os rótulos
labels_df = pd.read_csv(labels_path)

# Verificar as primeiras linhas dos rótulos
print(labels_df.head())

# Verificar se o número de rótulos corresponde ao número de imagens
print(f"Total de rótulos: {len(labels_df)}")
print(f"Total de imagens no diretório: {len(os.listdir(image_dir))}")

# Redimensionar as imagens e criar arrays para as imagens e rótulos
resized_images = []
labels = []

for _, row in labels_df.iterrows():
    img_id = row['id']  # ID da imagem
    label = row['label']  # Rótulo da imagem
    img_path = os.path.join(image_dir, f"{img_id}.tif")  # Caminho da imagem

    # Verificar se o arquivo de imagem existe
    if os.path.exists(img_path):
        img = cv2.imread(img_path)
        img = cv2.resize(img, (32, 32))  # Redimensionar para 32x32 pixels
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Converter para RGB

        resized_images.append(img)
        labels.append(label)

# Converter para arrays do NumPy
import numpy as np

resized_images = np.array(resized_images)
labels = np.array(labels)

print(f"Total de imagens redimensionadas: {len(resized_images)}")
print(f"Total de rótulos associados: {len(labels)}")

from sklearn.model_selection import train_test_split

# Dividir os dados em conjuntos de treino e validação
X_train, X_val, y_train, y_val = train_test_split(resized_images, labels, test_size=0.2, random_state=42)

print(f"Conjunto de treino: {len(X_train)} imagens")
print(f"Conjunto de validação: {len(X_val)} imagens")

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.utils import to_categorical

# Converter os rótulos para one-hot encoding
y_train_categorical = to_categorical(y_train)
y_val_categorical = to_categorical(y_val)

# Criar o modelo CNN
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),
    MaxPooling2D((2, 2)),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(2, activation='softmax')  # Duas classes: tumor ou não tumor
])

# Compilar o modelo
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Resumo do modelo
model.summary()

history = model.fit(
    X_train, y_train_categorical,
    validation_data=(X_val, y_val_categorical),
    epochs=10,
    batch_size=32
)

# Avaliar o modelo no conjunto de validação
val_loss, val_accuracy = model.evaluate(X_val, y_val_categorical)
print(f"Acurácia na validação: {val_accuracy * 100:.2f}%")

# Salvar o modelo treinado
model.save('/content/drive/MyDrive/kaggle/cancer_detection_model.h5')

# Assumindo que o DataFrame 'train_labels' tem a coluna 'label' para os rótulos de cada imagem
labels = train_labels['label'].values  # Substitua 'label' pelo nome correto da coluna de rótulos

# Verificar o número de imagens e rótulos
print(f"Número de imagens redimensionadas: {len(resized_images)}")
print(f"Número de rótulos: {len(labels)}")

import os

image_dir = '/content/train_extracted'  # Diretório onde as imagens foram extraídas

# Verificar os arquivos no diretório
image_files = os.listdir(image_dir)

# Exibir os primeiros 10 arquivos para confirmar que há imagens
print(image_files[:10])

# Filtrar apenas arquivos de imagem (exemplo: .jpg, .png)
image_files = [f for f in os.listdir(image_dir) if f.endswith(('.jpg', '.png'))]

# Verificar se temos imagens válidas
print(f"Total de imagens encontradas: {len(image_files)}")

import os

# Verificar os arquivos no diretório atual
print(os.listdir('/content'))

zip_image_path = '/content/drive/MyDrive/kaggle/train.zip'

import matplotlib.pyplot as plt
import cv2
import os

# Caminho para o diretório de imagens
image_dir = '/content/train_extracted'  # Ajuste o caminho para o diretório correto

# Verifique se o diretório de imagens existe
if not os.path.exists(image_dir):
    print(f"Erro: O diretório {image_dir} não existe.")
else:
    # Mostrar algumas imagens
    fig, axes = plt.subplots(1, 5, figsize=(15, 5))
    for i, ax in enumerate(axes):
        try:
            # Pegar ID da imagem e caminho completo
            img_id = train_labels.loc[i, 'id']  # Certifique-se de que 'id' seja uma coluna em train_labels
            img_path = os.path.join(image_dir, f"{img_id}.tif")  # Adapte a extensão conforme necessário

            # Carregar a imagem
            image = cv2.imread(img_path)
            if image is None:
                raise FileNotFoundError(f"Imagem {img_id} não encontrada em {img_path}")

            # Converter e mostrar
            ax.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
            ax.set_title(f"Label: {train_labels.loc[i, 'label']}")
            ax.axis('off')
        except Exception as e:
            print(f"Erro ao carregar a imagem {img_id}: {e}")
            ax.axis('off')  # Desativar o eixo mesmo em caso de erro

    plt.tight_layout()
    plt.show()

print(train_labels.head())

import pandas as pd

# Caminho para o arquivo CSV
labels_path = '/content/drive/MyDrive/kaggle/train_labels.csv'

# Carregar o arquivo CSV
train_labels = pd.read_csv(labels_path)

# Mostrar as primeiras linhas para verificar
print(train_labels.head())

def display_images(img_ids, labels, path, title):
    plt.figure(figsize=(15, 5))
    for i, (img_id, label) in enumerate(zip(img_ids, labels)):
        img_path = os.path.join(path, img_id + '.tif')
        img = Image.open(img_path)
        plt.subplot(1, len(img_ids), i + 1)
        plt.imshow(img)
        plt.title(f"Label: {label}")
        plt.axis('off')
    plt.suptitle(title)
    plt.show()

# Show examples with and without cancer
display_images(train_labels[train_labels['label'] == 0]['id'][:5], [0]*5, train_dir, "Images Without Cancer")
display_images(train_labels[train_labels['label'] == 1]['id'][:5], [1]*5, train_dir, "Images With Cancer")

"""Model Architecture and Training"""



#A taxa de aprenzidado
learning_rate = 0.001
opt = keras.optimizers.Adam(learning_rate = learning_rate)
model.compile(optimizer=opt, loss='binary_crossentropy',
              metrics=['accuracy'])
model.summary()

from sklearn.model_selection import train_test_split

train_label, val_label = train_test_split(train_labels, test_size=0.15, random_state=10)
train_label.info(), train_label.head()

train_label['label'] = train_label['label'].astype(str)
val_label['label'] = val_label['label'].astype(str)

train_label['filename'] = train_labels['id'] + '.tif'
val_label['filename'] = val_label['id'] + '.tif'
train_label.head()

"""
**ANALISES E RESULTADOS**

Várias configurações experimentais foram conduzidas para melhorar o modelo.
Ajuste de Hiperparâmetros: Foi utilizada validação cruzada para selecionar os hiperparâmetros ótimos.
Comparações: Comparei diferentes arquiteturas de modelos, incluindo redes mais profundas, para avaliar o desempenho.
Otimização do Treinamento: Técnicas como parada precoce e redução da taxa de aprendizado melhoraram a convergência.
Métricas de Desempenho: Foram utilizadas acurácia e AUC-ROC para avaliar o modelo, com os resultados apresentados em tabelas e gráficos comparativos.
Resumo:

Este texto descreve as etapas realizadas para melhorar o desempenho de um modelo de aprendizado de máquina. Foram utilizadas várias técnicas para otimizar o modelo, incluindo:

Ajuste de Hiperparâmetros: A validação cruzada foi empregada para encontrar os melhores valores para os parâmetros do modelo.
Experimentação com Arquiteturas: Foram testadas diferentes estruturas de modelos, como redes neurais mais complexas, para identificar a melhor configuração.
Otimização do Treinamento: Foram aplicadas técnicas como a parada precoce (interromper o treinamento antes do overfitting) e a redução da taxa de aprendizado para melhorar a convergência do treinamento.
Por fim, o desempenho do modelo foi avaliado utilizando métricas como acurácia e AUC-ROC, e os resultados foram apresentados de forma clara e comparativa."""

history_2 = model_2.fit(train_generator, epochs=5, validation_data = val_generator)
history_2

lr = 0.001
opt = keras.optimizers.Adam(learning_rate=lr)
model_2.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])

model_2.summary()

learning_curve(history_2)

from keras.callbacks import EarlyStopping

# Early stopping
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# Model fitting
history_3 = model_3.fit(train_generator,
                        epochs = 7,
                        validation_data = val_generator,
                        callbacks = [early_stopping])

history_3

learning_curve(history_3)



# Preparar o gerador de dados de teste
test_datagen = ImageDataGenerator(rescale=1./255)

test_generator = test_datagen.flow_from_dataframe(
    dataframe=pd.DataFrame({'id': os.listdir(test_dir)}),
    directory=test_dir,
    x_col='id',
    y_col=None,
    target_size=(96, 96),
    batch_size=32,
    class_mode=None,
    shuffle=False
)

# Reiniciar o gerador de teste
test_generator.reset()

# Fazer previsões
predictions = model_3.predict(test_generator, steps=test_generator.samples)

# Preparar o DataFrame para submissão
filenames = test_generator.filenames
ids = [filename.split('.')[0] for filename in filenames]
predicted_labels = (predictions > 0.5).astype(int).reshape(-1)

submission_df = pd.DataFrame({
    'id': ids,
    'label': predicted_labels
})

# Salvar o arquivo de submissão
submission_df.to_csv('submission_model3_final.csv', index=False)
'/kaggle/input/histopathologic-cancer-detection/'

"""**Conclusão**

Neste mini projeto, três modelos. Um com duas camadas de convolução, outro com quatro camadas de convolução com normalização por lote (batch normalization) e dropout. O terceiro modelo variou a taxa de aprendizado e o número de épocas do segundo modelo.

Na validação usando os dados de treinamento, o modelo 3 registrou a pontuação mais alta, e o erro de entropia cruzada também diminuiu de forma mais estável do que no modelo 2. Ao reduzir a taxa de aprendizado instável para 0,0001 e aumentar o número de épocas, o modelo conseguiu obter pesos melhores.

O treinamento levou muito tempo, especialmente para o modelo 3. Parece que o modelo 3 superajustou os dados de treinamento, resultando em uma diferença entre a precisão de validação e a precisão de teste. Pode ter sido necessário gerar mais tipos de dados de imagem com o ImageDataGenerator.

Resumo:

Este mini projeto envolveu a comparação de três modelos de redes convolucionais para uma tarefa de classificação de imagens.

Modelo 1: Simples, com duas camadas de convolução.
Modelo 2: Mais complexo, com quatro camadas de convolução, normalização por lote e dropout.
Modelo 3: Baseado no Modelo 2, com ajuste da taxa de aprendizado e do número de épocas de treinamento.
O Modelo 3 apresentou o melhor desempenho na validação interna, mas pode ter ocorrido overfitting, levando a uma diferença significativa entre a performance no conjunto de treinamento e no conjunto de teste.

Para melhorar os resultados, sugere-se a utilização de técnicas de aumento de dados (como o ImageDataGenerator) para aumentar a diversidade das imagens de treinamento e evitar o overfitting.
"""